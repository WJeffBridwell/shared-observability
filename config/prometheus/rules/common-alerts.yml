groups:
  - name: service-availability
    rules:
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute."

      - alert: ContainerRestarting
        expr: increase(container_restarts_total[1h]) > 3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.name }} is restarting frequently"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last hour."

  - name: http-metrics
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[2m])) by (service)
          /
          sum(rate(http_requests_total[2m])) by (service) > 0.05
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate for {{ $labels.service }}"
          description: "{{ $labels.service }} has error rate of {{ $value | humanizePercentage }} over the last 2 minutes."

      - alert: HighLatency
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency for {{ $labels.service }}"
          description: "{{ $labels.service }} P95 latency is {{ $value | humanizeDuration }}."

  - name: host-resources
    rules:
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}."

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}."

      - alert: DiskSpaceWarning
        expr: (1 - node_filesystem_avail_bytes{fstype!~"tmpfs|overlay|erofs",mountpoint!~"/oldroot.*"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay|erofs",mountpoint!~"/oldroot.*"}) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk usage above 85% on {{ $labels.instance }}"
          description: "Disk {{ $labels.mountpoint }} on {{ $labels.instance }} is at {{ $value | humanizePercentage }} usage."

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay|erofs",mountpoint!~"/oldroot.*"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay|erofs",mountpoint!~"/oldroot.*"}) < 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk {{ $labels.mountpoint }} on {{ $labels.instance }} has only {{ $value | humanizePercentage }} free."

  - name: blackbox-probes
    rules:
      - alert: EndpointDown
        expr: probe_success{job!="blackbox-icmp"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Endpoint {{ $labels.instance }} is down"
          description: "Blackbox probe for {{ $labels.instance }} (job {{ $labels.job }}) has been failing for 2 minutes."

  # HighErrorLogRate moved to Grafana Loki-based alerting (contact-points.yaml).
  # LogQL expressions cannot evaluate in Prometheus â€” only Loki ruler or Grafana.
